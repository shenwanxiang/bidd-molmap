{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/sxh/Research/AttentiveFP/code',)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss\n",
    "\n",
    "\n",
    "\n",
    "def predict(model, dataset):\n",
    "    model.eval()\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch) \n",
    "        \n",
    "    preds = []\n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "#         print(batch_df)\n",
    "        y_val = batch_df[tasks[0]].values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        probs = F.softmax(mol_prediction,dim=-1).data.cpu().numpy()[:,1]\n",
    "        preds.append(probs)\n",
    "    return np.concatenate(preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  1513\n",
      "number of successfully processed smiles:  1513\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tasks = ['Class']\n",
    "raw_filename = \"/home/sxh/Research/AttentiveFP/data/bace.csv\"\n",
    "\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.mol.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"mol\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 88\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "\n",
    "radius = 3\n",
    "T = 2\n",
    "weight_decay = 2.9 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mol</th>\n",
       "      <th>CID</th>\n",
       "      <th>Class</th>\n",
       "      <th>Model</th>\n",
       "      <th>pIC50</th>\n",
       "      <th>MW</th>\n",
       "      <th>AlogP</th>\n",
       "      <th>HBA</th>\n",
       "      <th>HBD</th>\n",
       "      <th>RB</th>\n",
       "      <th>...</th>\n",
       "      <th>PEOE7 (PEOE7)</th>\n",
       "      <th>PEOE8 (PEOE8)</th>\n",
       "      <th>PEOE9 (PEOE9)</th>\n",
       "      <th>PEOE10 (PEOE10)</th>\n",
       "      <th>PEOE11 (PEOE11)</th>\n",
       "      <th>PEOE12 (PEOE12)</th>\n",
       "      <th>PEOE13 (PEOE13)</th>\n",
       "      <th>PEOE14 (PEOE14)</th>\n",
       "      <th>canvasUID</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [mol, CID, Class, Model, pIC50, MW, AlogP, HBA, HBD, RB, HeavyAtomCount, ChiralCenterCount, ChiralCenterCountAllPossible, RingCount, PSA, Estate, MR, Polar, sLi_Key, ssBe_Key, ssssBem_Key, sBH2_Key, ssBH_Key, sssB_Key, ssssBm_Key, sCH3_Key, dCH2_Key, ssCH2_Key, tCH_Key, dsCH_Key, aaCH_Key, sssCH_Key, ddC_Key, tsC_Key, dssC_Key, aasC_Key, aaaC_Key, ssssC_Key, sNH3_Key, sNH2_Key, ssNH2_Key, dNH_Key, ssNH_Key, aaNH_Key, tN_Key, sssNH_Key, dsN_Key, aaN_Key, sssN_Key, ddsN_Key, aasN_Key, ssssN_Key, daaN_Key, sOH_Key, dO_Key, ssO_Key, aaO_Key, aOm_Key, sOm_Key, sF_Key, sSiH3_Key, ssSiH2_Key, sssSiH_Key, ssssSi_Key, sPH2_Key, ssPH_Key, sssP_Key, dsssP_Key, ddsP_Key, sssssP_Key, sSH_Key, dS_Key, ssS_Key, aaS_Key, dssS_Key, ddssS_Key, ssssssS_Key, Sm_Key, sCl_Key, sGeH3_Key, ssGeH2_Key, sssGeH_Key, ssssGe_Key, sAsH2_Key, ssAsH_Key, sssAs_Key, dsssAs_Key, ddsAs_Key, sssssAs_Key, sSeH_Key, dSe_Key, ssSe_Key, aaSe_Key, dssSe_Key, ssssssSe_Key, ddssSe_Key, sBr_Key, sSnH3_Key, ssSnH2_Key, sssSnH_Key, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 596 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/raid/shenwanxiang/08_Robustness/dataset_induces/split\"\n",
    "random_seeds = [2, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir /raid/shenwanxiang/08_Robustness/saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 BACE\n",
      "16 BACE\n",
      "32 BACE\n",
      "64 BACE\n",
      "128 BACE\n",
      "256 BACE\n",
      "512 BACE\n",
      "1024 BACE\n",
      "2048 BACE\n",
      "4096 BACE\n"
     ]
    }
   ],
   "source": [
    "remained_df = remained_df.reset_index(drop=True)\n",
    "task_name = 'BACE'\n",
    "\n",
    "for seed in random_seeds:\n",
    "    \n",
    "    train_path = os.path.join(file_path, task_name,\"%s\" % seed, \"train.csv\")\n",
    "    valid_path = os.path.join(file_path, task_name,\"%s\" % seed, \"val.csv\")\n",
    "    test_path = os.path.join(file_path, task_name,\"%s\" % seed, \"test.csv\")\n",
    "\n",
    "    pred_valid_path = os.path.join(file_path, task_name,\"%s\" % seed, \"attfp_pred_val.csv\")\n",
    "    pred_test_path = os.path.join(file_path, task_name,\"%s\" % seed, \"attfp_pred_test.csv\")\n",
    "    \n",
    "    saved_valid_path = os.path.join(file_path, task_name,\"%s\" % seed, \"attfp_saved_val.csv\")\n",
    "    saved_test_path = os.path.join(file_path, task_name,\"%s\" % seed, \"attfp_saved_test.csv\")\n",
    "    \n",
    "    \n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_valid = pd.read_csv(valid_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "\n",
    "    print(seed, task_name)\n",
    "    \n",
    "    if (os.path.exists(pred_test_path)) & (os.path.exists(pred_valid_path)):\n",
    "        continue\n",
    "\n",
    "    \n",
    "\n",
    "    test_df = remained_df[remained_df.mol.isin(df_test.smiles)].reset_index(drop=True)\n",
    "    valid_df = remained_df[remained_df.mol.isin(df_valid.smiles)].reset_index(drop=True)\n",
    "    train_df = remained_df[remained_df.mol.isin(df_train.smiles)].reset_index(drop=True)\n",
    "\n",
    "    weights = []\n",
    "    for i,task in enumerate(tasks):    \n",
    "        negative_df = train_df[train_df[task] == 0][[\"mol\",task]]\n",
    "        positive_df = train_df[train_df[task] == 1][[\"mol\",task]]\n",
    "        weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                        (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "\n",
    "\n",
    "    print(len(train_df),len(valid_df),len(test_df),)\n",
    "\n",
    "    x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([canonical_smiles_list[0]],feature_dicts)\n",
    "    num_atom_features = x_atom.shape[-1]\n",
    "    num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "    loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight)) for weight in weights]\n",
    "    model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "                fingerprint_dim, output_units_num, p_dropout)\n",
    "    model.cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "\n",
    "    best_param ={}\n",
    "    best_param[\"roc_epoch\"] = 0\n",
    "    best_param[\"loss_epoch\"] = 0\n",
    "    best_param[\"valid_roc\"] = 0\n",
    "    best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "    for epoch in range(epochs):    \n",
    "        train_roc, train_prc, train_precision, train_recall, train_loss = eval(model, train_df)\n",
    "        valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = eval(model, valid_df)\n",
    "        train_roc_mean = np.array(train_roc).mean()\n",
    "        valid_roc_mean = np.array(valid_roc).mean()\n",
    "\n",
    "        if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "            best_param[\"roc_epoch\"] = epoch\n",
    "            best_param[\"valid_roc\"] = valid_roc_mean\n",
    "            if valid_roc_mean > 0.77:\n",
    "                 torch.save(model, '/raid/shenwanxiang/08_Robustness/saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')\n",
    "\n",
    "        if valid_loss < best_param[\"valid_loss\"]:\n",
    "            best_param[\"loss_epoch\"] = epoch\n",
    "            best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "        print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "            +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "            +\"valid_roc\"+\":\"+str(valid_roc)+'\\n')\n",
    "        if epoch - best_param[\"roc_epoch\"] > 10:        \n",
    "            break\n",
    "\n",
    "        train(model, train_df, optimizer, loss_function)\n",
    "\n",
    "    # evaluate model\n",
    "    best_model = torch.load('/raid/shenwanxiang/08_Robustness/saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "    test_roc, test_prc, test_precision, test_recall, test_losses = eval(best_model, test_df)\n",
    "\n",
    "    print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "          +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "          +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "         )\n",
    "\n",
    "\n",
    "    pred_test = predict(best_model, test_df)\n",
    "    pd.DataFrame(pred_test, index = test_df['mol'],\n",
    "                 columns = [task_name]).to_csv(pred_test_path)\n",
    "\n",
    "    pd.DataFrame(test_df[tasks].values, index = test_df['mol'],\n",
    "                 columns = [task_name]).to_csv(saved_test_path)\n",
    "\n",
    "    pred_valid = predict(best_model, valid_df)\n",
    "    pd.DataFrame(pred_valid, index = valid_df['mol'], \n",
    "                 columns = [task_name]).to_csv(pred_valid_path)\n",
    "\n",
    "    pd.DataFrame(valid_df[tasks].values, index = valid_df['mol'],\n",
    "                 columns = [task_name]).to_csv(saved_valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_gpu4_run_ESOL.ipynb      06_gpu7_HIV.ipynb\n",
      "02_gpu3_run_FreeSolv.ipynb  07_gpu4_run_pdbr.ipynb\n",
      "02_gpu3_run_Malaria.ipynb   08_gpu5_ClinTox.ipynb\n",
      "03_gpu4_lipop.ipynb         09_gpu6_Tox21.ipynb\n",
      "04_gpup4_BACE.ipynb         attentivefp.random.final.csv\n",
      "05_gpu1_BBBP.ipynb          ZZZ_eva_rd5fcv.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
